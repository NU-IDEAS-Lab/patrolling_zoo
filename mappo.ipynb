{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPO Integration\n",
    "\n",
    "This runs the integrated MAPPO algorithm with the patrolling zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from onpolicy.scripts.train.train_patrolling import get_config, parse_args, main\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_config()\n",
    "all_args = parse_args([], parser)\n",
    "\n",
    "all_args.experiment_name = \"bitmap\"\n",
    "all_args.env_name = \"Patrolling\"\n",
    "all_args.user_name = \"anthony-goeckner\"\n",
    "\n",
    "all_args.num_agents = 2\n",
    "all_args.agent_speed = 10.0\n",
    "all_args.observe_method = \"bitmap\"\n",
    "\n",
    "all_args.graph_name = \"4nodes\"\n",
    "all_args.graph_file = f\"patrolling_zoo/env/{all_args.graph_name}.graph\"\n",
    "all_args.num_env_steps = 10e4 #total number of steps\n",
    "all_args.episode_length = 50 #number of steps in a training episode\n",
    "all_args.max_cycles = 200 #number of steps in an environment episode\n",
    "\n",
    "all_args.algorithm_name = \"rmappo\"\n",
    "all_args.use_recurrent_policy = True\n",
    "all_args.use_naive_recurrent_policy = False\n",
    "all_args.use_centralized_V = True\n",
    "\n",
    "all_args.n_rollout_threads = 25\n",
    "all_args.cuda = True\n",
    "all_args.cuda_index = 0\n",
    "\n",
    "all_args.use_wandb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u are choosing to use rmappo, we set use_recurrent_policy to be True\n",
      "choose to use gpu...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Anthony\\Development\\patrolling_zoo2\\onpolicy\\scripts\\results\\Patrolling\\4nodes\\rmappo\\bitmap\\wandb\\run-20230821_173750-l1d0urif</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anthony-goeckner/Patrolling/runs/l1d0urif' target=\"_blank\">rmappo-bitmap-20230821-173750-seed1</a></strong> to <a href='https://wandb.ai/anthony-goeckner/Patrolling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anthony-goeckner/Patrolling' target=\"_blank\">https://wandb.ai/anthony-goeckner/Patrolling</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anthony-goeckner/Patrolling/runs/l1d0urif' target=\"_blank\">https://wandb.ai/anthony-goeckner/Patrolling/runs/l1d0urif</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 0/80 episodes, total num timesteps 1250/100000.0, FPS 141.\n",
      "\n",
      "average episode rewards is 28341.677856445312\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 1/80 episodes, total num timesteps 2500/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 31816.580200195312\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 2/80 episodes, total num timesteps 3750/100000.0, FPS 155.\n",
      "\n",
      "average episode rewards is 26624.411010742188\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 3/80 episodes, total num timesteps 5000/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 28177.301025390625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 4/80 episodes, total num timesteps 6250/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 29955.694580078125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 5/80 episodes, total num timesteps 7500/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 29325.1708984375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 6/80 episodes, total num timesteps 8750/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 30603.890991210938\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 7/80 episodes, total num timesteps 10000/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 29780.755615234375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 8/80 episodes, total num timesteps 11250/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 30972.674560546875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 9/80 episodes, total num timesteps 12500/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 36508.77990722656\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 10/80 episodes, total num timesteps 13750/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 27367.510986328125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 11/80 episodes, total num timesteps 15000/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 32118.0908203125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 12/80 episodes, total num timesteps 16250/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 32793.78967285156\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 13/80 episodes, total num timesteps 17500/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 33928.021240234375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 14/80 episodes, total num timesteps 18750/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 31772.100830078125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 15/80 episodes, total num timesteps 20000/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 32100.900268554688\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 16/80 episodes, total num timesteps 21250/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 38036.01379394531\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 17/80 episodes, total num timesteps 22500/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 35841.00036621094\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 18/80 episodes, total num timesteps 23750/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 31717.535400390625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 19/80 episodes, total num timesteps 25000/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 36835.16540527344\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 20/80 episodes, total num timesteps 26250/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 38713.525390625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 21/80 episodes, total num timesteps 27500/100000.0, FPS 159.\n",
      "\n",
      "average episode rewards is 37129.86145019531\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 22/80 episodes, total num timesteps 28750/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 38582.47375488281\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 23/80 episodes, total num timesteps 30000/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 33533.45642089844\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 24/80 episodes, total num timesteps 31250/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 35390.679931640625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 25/80 episodes, total num timesteps 32500/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 34903.01818847656\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 26/80 episodes, total num timesteps 33750/100000.0, FPS 158.\n",
      "\n",
      "average episode rewards is 39147.906494140625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 27/80 episodes, total num timesteps 35000/100000.0, FPS 157.\n",
      "\n",
      "average episode rewards is 37023.79455566406\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 28/80 episodes, total num timesteps 36250/100000.0, FPS 157.\n",
      "\n",
      "average episode rewards is 32666.488647460938\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 29/80 episodes, total num timesteps 37500/100000.0, FPS 157.\n",
      "\n",
      "average episode rewards is 36723.980712890625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 30/80 episodes, total num timesteps 38750/100000.0, FPS 156.\n",
      "\n",
      "average episode rewards is 31684.970092773438\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 31/80 episodes, total num timesteps 40000/100000.0, FPS 156.\n",
      "\n",
      "average episode rewards is 47418.85070800781\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 32/80 episodes, total num timesteps 41250/100000.0, FPS 155.\n",
      "\n",
      "average episode rewards is 40504.57458496094\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 33/80 episodes, total num timesteps 42500/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 37920.428466796875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 34/80 episodes, total num timesteps 43750/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 38397.12829589844\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 35/80 episodes, total num timesteps 45000/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 38779.04968261719\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 36/80 episodes, total num timesteps 46250/100000.0, FPS 151.\n",
      "\n",
      "average episode rewards is 43508.69445800781\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 37/80 episodes, total num timesteps 47500/100000.0, FPS 151.\n",
      "\n",
      "average episode rewards is 41943.29528808594\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 38/80 episodes, total num timesteps 48750/100000.0, FPS 151.\n",
      "\n",
      "average episode rewards is 48235.3759765625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 39/80 episodes, total num timesteps 50000/100000.0, FPS 151.\n",
      "\n",
      "average episode rewards is 48661.761474609375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 40/80 episodes, total num timesteps 51250/100000.0, FPS 151.\n",
      "\n",
      "average episode rewards is 46159.930419921875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 41/80 episodes, total num timesteps 52500/100000.0, FPS 151.\n",
      "\n",
      "average episode rewards is 47076.44348144531\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 42/80 episodes, total num timesteps 53750/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 48288.98620605469\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 43/80 episodes, total num timesteps 55000/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 38134.466552734375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 44/80 episodes, total num timesteps 56250/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 33673.712158203125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 45/80 episodes, total num timesteps 57500/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 36441.56494140625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 46/80 episodes, total num timesteps 58750/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 45378.77502441406\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 47/80 episodes, total num timesteps 60000/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 42430.51452636719\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 48/80 episodes, total num timesteps 61250/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 49965.73486328125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 49/80 episodes, total num timesteps 62500/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 49034.051513671875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 50/80 episodes, total num timesteps 63750/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 47628.18908691406\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 51/80 episodes, total num timesteps 65000/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 49129.010009765625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 52/80 episodes, total num timesteps 66250/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 47870.69091796875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 53/80 episodes, total num timesteps 67500/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 45586.346435546875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 54/80 episodes, total num timesteps 68750/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 57015.6982421875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 55/80 episodes, total num timesteps 70000/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 54140.301513671875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 56/80 episodes, total num timesteps 71250/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 51461.151123046875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 57/80 episodes, total num timesteps 72500/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 54623.236083984375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 58/80 episodes, total num timesteps 73750/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 54927.069091796875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 59/80 episodes, total num timesteps 75000/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 54952.850341796875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 60/80 episodes, total num timesteps 76250/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 51468.5302734375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 61/80 episodes, total num timesteps 77500/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 55721.52099609375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 62/80 episodes, total num timesteps 78750/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 49340.203857421875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 63/80 episodes, total num timesteps 80000/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 49274.01428222656\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 64/80 episodes, total num timesteps 81250/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 54078.662109375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 65/80 episodes, total num timesteps 82500/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 55337.310791015625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 66/80 episodes, total num timesteps 83750/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 52665.411376953125\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 67/80 episodes, total num timesteps 85000/100000.0, FPS 154.\n",
      "\n",
      "average episode rewards is 56431.097412109375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 68/80 episodes, total num timesteps 86250/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 55485.882568359375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 69/80 episodes, total num timesteps 87500/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 58379.3212890625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 70/80 episodes, total num timesteps 88750/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 55215.80810546875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 71/80 episodes, total num timesteps 90000/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 53743.212890625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 72/80 episodes, total num timesteps 91250/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 54033.8623046875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 73/80 episodes, total num timesteps 92500/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 63449.8779296875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 74/80 episodes, total num timesteps 93750/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 62238.96484375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 75/80 episodes, total num timesteps 95000/100000.0, FPS 153.\n",
      "\n",
      "average episode rewards is 53588.690185546875\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 76/80 episodes, total num timesteps 96250/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 50158.23974609375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 77/80 episodes, total num timesteps 97500/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 60290.667724609375\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 78/80 episodes, total num timesteps 98750/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 54770.37353515625\n",
      "\n",
      " Env Patrolling Algo rmappo Exp bitmap updates 79/80 episodes, total num timesteps 100000/100000.0, FPS 152.\n",
      "\n",
      "average episode rewards is 60918.95751953125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_grad_norm</td><td>▁▁▄▂▂▂▄▂▂█▂▂▅▇▃▂▄▃▅▄▃▂▅▂▂▂▆▅▃▃▇▄▂▂▅▄▃▂▆▃</td></tr><tr><td>average_episode_rewards</td><td>▁▁▂▂▂▁▂▂▃▂▃▃▃▃▂▂▄▃▄▅▅▅▂▅▆▅▅▇▆▇▆▅▆▆▇▇▆█▆█</td></tr><tr><td>avg_idleness</td><td>▆█▇▇▇▇▆▆▅▅▅▄▅▄▅▅▄▄▄▃▃▃▅▄▂▃▃▂▂▂▂▂▁▂▁▁▁▁▂▁</td></tr><tr><td>critic_grad_norm</td><td>█▂▂▂▂▁▂▁▂▁▂▁▂▁▂▁▂▁▂▁▂▁▁▁▂▁▂▁▂▁▂▁▂▁▂▁▂▁▂▂</td></tr><tr><td>dist_entropy</td><td>██▇▇▇▇▇▇▇▆▇▆▆▆▆▆▆▆▆▅▅▅▅▄▅▄▄▃▄▃▃▂▃▂▂▁▂▁▂▁</td></tr><tr><td>policy_loss</td><td>▁▁▄▂▂▃▄▄▂▆▃▄▃█▃▃▄▃▃▃▄▅▂▃▃▂▃▅▄▂▆▃▄▃▁▄▃▄▆▂</td></tr><tr><td>ratio</td><td>▅▄▆▄▄▅▄▄▄▅▆▄▄▅▄▃▅▅▅▃▅▇▅▅▅▆█▄▄▄▃▅▃▃▄▄▁▆▃▅</td></tr><tr><td>value_loss</td><td>█▂▃▃▃▂▃▂▃▂▃▂▂▂▁▁▂▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_grad_norm</td><td>0.59019</td></tr><tr><td>average_episode_rewards</td><td>60918.95752</td></tr><tr><td>avg_idleness</td><td>7.25</td></tr><tr><td>critic_grad_norm</td><td>3.98415</td></tr><tr><td>dist_entropy</td><td>0.66091</td></tr><tr><td>policy_loss</td><td>-0.00505</td></tr><tr><td>ratio</td><td>1.00091</td></tr><tr><td>value_loss</td><td>0.48595</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rmappo-bitmap-20230821-173750-seed1</strong> at: <a href='https://wandb.ai/anthony-goeckner/Patrolling/runs/l1d0urif' target=\"_blank\">https://wandb.ai/anthony-goeckner/Patrolling/runs/l1d0urif</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\onpolicy\\scripts\\results\\Patrolling\\4nodes\\rmappo\\bitmap\\wandb\\run-20230821_173750-l1d0urif\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main([], parsed_args = all_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patrolling_zoo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
