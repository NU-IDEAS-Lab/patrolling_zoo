{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPO Integration\n",
    "\n",
    "This runs the integrated MAPPO algorithm with the patrolling zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from onpolicy.scripts.train.train_patrolling import get_config, parse_args, main\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onpolicy.scripts.train.train_patrolling import get_config, parse_args, main\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\"\n",
    "\n",
    "parser = get_config()\n",
    "all_args = parse_args([], parser)\n",
    "\n",
    "all_args.experiment_name = \"nbrScoringDepth10JKAggrAddAgentID\"\n",
    "all_args.env_name = \"Patrolling\"\n",
    "all_args.user_name = \"ideas-mas\"\n",
    "\n",
    "all_args.num_agents = 4\n",
    "all_args.agent_speed = 40.0\n",
    "all_args.action_method = \"neighbors\"\n",
    "all_args.observe_method = \"pyg\"\n",
    "all_args.observe_method_global = \"adjacency\"\n",
    "all_args.observation_radius = 400.0\n",
    "all_args.observation_bitmap_size = 40\n",
    "all_args.communication_model = \"bernoulli\"\n",
    "all_args.communication_probability = 0.1\n",
    "all_args.alpha = 1.0\n",
    "all_args.beta = 0.5\n",
    "# all_args.reward_method_terminal = \"averageAverage\"\n",
    "all_args.reward_method_terminal = \"average\"\n",
    "# all_args.reward_interval = 1\n",
    "\n",
    "# all_args.graph_random = True\n",
    "# all_args.graph_random_nodes = 9\n",
    "all_args.graph_name = \"milwaukee\"\n",
    "all_args.graph_file = f\"patrolling_zoo/env/{all_args.graph_name}.graph\"\n",
    "# all_args.num_env_steps = 10000 #total number of steps\n",
    "all_args.num_env_steps = 10e5 * 1 #total number of steps\n",
    "all_args.episode_length = 200 #number of steps in a training episode\n",
    "all_args.max_cycles = all_args.episode_length #number of steps in an environment episode\n",
    "\n",
    "all_args.algorithm_name = \"mappo\"\n",
    "all_args.use_gnn_policy = True\n",
    "all_args.use_gnn_mlp_policy = True\n",
    "all_args.gnn_layer_N = 10\n",
    "all_args.gnn_hidden_size = 128\n",
    "all_args.gnn_skip_connections = True\n",
    "all_args.use_recurrent_policy = True\n",
    "all_args.use_naive_recurrent_policy = False\n",
    "all_args.use_centralized_V = True\n",
    "all_args.use_gae = False\n",
    "all_args.use_gae_amadm = True\n",
    "all_args.share_policy = True\n",
    "all_args.sep_share_policy = False\n",
    "all_args.share_reward = False\n",
    "all_args.skip_steps_sync = True\n",
    "all_args.skip_steps_async = False\n",
    "all_args.use_ReLU = True\n",
    "# all_args.lr = 1e-3\n",
    "# all_args.entropy_coef = 0.1\n",
    "all_args.hidden_size = 512\n",
    "\n",
    "all_args.n_rollout_threads = 1\n",
    "all_args.save_interval = 1000\n",
    "all_args.cuda = True\n",
    "all_args.cuda_idx = 4\n",
    "\n",
    "all_args.use_wandb = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u are choosing to use mappo, we set use_recurrent_policy & use_naive_recurrent_policy to be False\n",
      "choose to use gpu...\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 0/5000 episodes, total num timesteps 200/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 44.42111551761627 and idleness is 73.9\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 1/5000 episodes, total num timesteps 400/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 37.95272409915924 and idleness is 93.95\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 2/5000 episodes, total num timesteps 600/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 37.29374706745148 and idleness is 83.525\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 3/5000 episodes, total num timesteps 800/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 29.781067371368408 and idleness is 124.025\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 4/5000 episodes, total num timesteps 1000/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 33.679330348968506 and idleness is 113.1\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 5/5000 episodes, total num timesteps 1200/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 45.04309892654419 and idleness is 77.175\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 6/5000 episodes, total num timesteps 1400/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 46.84862792491913 and idleness is 67.075\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 7/5000 episodes, total num timesteps 1600/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 33.70983898639679 and idleness is 91.475\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 8/5000 episodes, total num timesteps 1800/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 29.88092005252838 and idleness is 125.0\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 9/5000 episodes, total num timesteps 2000/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 39.969757199287415 and idleness is 56.375\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 10/5000 episodes, total num timesteps 2200/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 46.81311547756195 and idleness is 92.5\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 11/5000 episodes, total num timesteps 2400/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 27.47960388660431 and idleness is 135.05\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 12/5000 episodes, total num timesteps 2600/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 40.26189148426056 and idleness is 55.8\n",
      "\n",
      " Env Patrolling Algo mappo Exp nbrScoringDepth10JKAggrAddAgentID updates 13/5000 episodes, total num timesteps 2800/1000000.0, FPS 14.\n",
      "\n",
      "average episode rewards is 31.57217800617218 and idleness is 92.8\n",
      "wandb due to keyboard interrupt\n"
     ]
    }
   ],
   "source": [
    "main([], parsed_args = all_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patrolling_zoo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
