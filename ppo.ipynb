{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Algorithm\n",
    "\n",
    "This code performs PPO on the Patrolling Zoo environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from patrolling_zoo.patrolling_zoo_v0 import parallel_env, PatrolGraph\n",
    "from algorithm.ppo import PPO\n",
    "\n",
    "# set process priority low\n",
    "import psutil\n",
    "import os\n",
    "if os.name == 'nt':\n",
    "    psutil.Process(os.getpid()).nice(psutil.BELOW_NORMAL_PRIORITY_CLASS)\n",
    "else:\n",
    "    psutil.Process(os.getpid()).nice(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "MAX_CYCLES = 500\n",
    "\n",
    "\"\"\" ENV SETUP \"\"\"\n",
    "patrolGraph = PatrolGraph(\"patrolling_zoo/env/4nodes.graph\")\n",
    "env = parallel_env(patrolGraph, 2,\n",
    "    require_explicit_visit = True,\n",
    "    speed = 5,\n",
    "    alpha = 1.0,\n",
    "    max_cycles = MAX_CYCLES,\n",
    "    observe_method = \"ajg_new\"\n",
    ")\n",
    "\n",
    "\"\"\"ALGO PARAMS\"\"\"\n",
    "algo = PPO(\n",
    "    env = env,\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    ent_coef = 0.1,\n",
    "    vf_coef = 0.1,\n",
    "    clip_coef = 0.1,\n",
    "    gamma = 0.99,\n",
    "    lr = 1e-4,\n",
    "    batch_size = 100,\n",
    "    max_cycles = MAX_CYCLES,\n",
    "    total_episodes = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# print(env.state())\n",
    "# print(env.state_space)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9975e-05.\n",
      "Training episode 0\n",
      "Episodic Return: -2096.615478515625\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9901e-05.\n",
      "Training episode 1\n",
      "Episodic Return: -1618.875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9778e-05.\n",
      "Training episode 2\n",
      "Episodic Return: 986.375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9606e-05.\n",
      "Training episode 3\n",
      "Episodic Return: 664.067626953125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9384e-05.\n",
      "Training episode 4\n",
      "Episodic Return: -901.8311767578125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9114e-05.\n",
      "Training episode 5\n",
      "Episodic Return: 1299.115966796875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8796e-05.\n",
      "Training episode 6\n",
      "Episodic Return: 587.3690185546875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8429e-05.\n",
      "Training episode 7\n",
      "Episodic Return: 1511.2950439453125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8015e-05.\n",
      "Training episode 8\n",
      "Episodic Return: 2441.25\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.7553e-05.\n",
      "Training episode 9\n",
      "Episodic Return: 579.142822265625\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.7044e-05.\n",
      "Training episode 10\n",
      "Episodic Return: 1511.0694580078125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.6489e-05.\n",
      "Training episode 11\n",
      "Episodic Return: 882.492919921875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5888e-05.\n",
      "Training episode 12\n",
      "Episodic Return: 4252.375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5241e-05.\n",
      "Training episode 13\n",
      "Episodic Return: -124.125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.4550e-05.\n",
      "Training episode 14\n",
      "Episodic Return: -615.8792724609375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3815e-05.\n",
      "Training episode 15\n",
      "Episodic Return: 83.75\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3037e-05.\n",
      "Training episode 16\n",
      "Episodic Return: -893.4140625\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.2216e-05.\n",
      "Training episode 17\n",
      "Episodic Return: -1234.105224609375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.1354e-05.\n",
      "Training episode 18\n",
      "Episodic Return: 599.4464111328125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0451e-05.\n",
      "Training episode 19\n",
      "Episodic Return: -2501.92919921875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.9508e-05.\n",
      "Training episode 20\n",
      "Episodic Return: 3246.25\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.8526e-05.\n",
      "Training episode 21\n",
      "Episodic Return: 230.55482482910156\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7506e-05.\n",
      "Training episode 22\n",
      "Episodic Return: 1556.7454833984375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.6448e-05.\n",
      "Training episode 23\n",
      "Episodic Return: 1233.125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5355e-05.\n",
      "Training episode 24\n",
      "Episodic Return: 823.2916870117188\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4227e-05.\n",
      "Training episode 25\n",
      "Episodic Return: -726.4942626953125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.3066e-05.\n",
      "Training episode 26\n",
      "Episodic Return: 1755.134765625\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1871e-05.\n",
      "Training episode 27\n",
      "Episodic Return: 1991.3875732421875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.0645e-05.\n",
      "Training episode 28\n",
      "Episodic Return: 1376.150634765625\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9389e-05.\n",
      "Training episode 29\n",
      "Episodic Return: -680.99755859375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8104e-05.\n",
      "Training episode 30\n",
      "Episodic Return: 1445.75\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6791e-05.\n",
      "Training episode 31\n",
      "Episodic Return: -578.912109375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.5452e-05.\n",
      "Training episode 32\n",
      "Episodic Return: 53.421142578125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4088e-05.\n",
      "Training episode 33\n",
      "Episodic Return: -699.491943359375\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.2700e-05.\n",
      "Training episode 34\n",
      "Episodic Return: -537.32861328125\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1289e-05.\n",
      "Training episode 35\n",
      "Episodic Return: 4207.875\n",
      "Episode Length: 499\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9857e-05.\n",
      "Training episode 36\n",
      "Episodic Return: 697.20458984375\n",
      "Episode Length: 499\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "stats = algo.train(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, figsize=(12, 6))\n",
    "fig.suptitle(\"Training Statistics per Episode\")\n",
    "\n",
    "ax[0, 0].set_title(\"Reward vs. Episode\")\n",
    "ax[0, 0].plot(stats[\"episodic_return\"])\n",
    "\n",
    "ax[1, 0].set_title(\"Iterations vs. Episode\")\n",
    "ax[1, 0].plot(stats[\"episodic_length\"])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(4, 2, sharex=True, figsize=(12, 10))\n",
    "fig.suptitle(\"Training Statistics per Iteration\")\n",
    "\n",
    "ax[0, 1].set_title(\"Value Loss vs. Iteration\")\n",
    "ax[0, 1].plot(stats[\"value_loss\"], label=\"value_loss\")\n",
    "# ax[0, 1].legend()\n",
    "\n",
    "ax[1, 0].set_title(\"Policy Loss vs. Iteration\")\n",
    "ax[1, 0].plot(stats[\"policy_loss\"], label=\"policy_loss\")\n",
    "# ax[1, 0].legend()\n",
    "\n",
    "ax[1, 1].set_title(\"Entropy Loss vs. Iteration\")\n",
    "ax[1, 1].plot(stats[\"entropy_loss\"], label=\"entropy_loss\")\n",
    "# ax[1, 1].legend()\n",
    "\n",
    "ax[2, 0].set_title(\"Total Loss vs. Iteration\")\n",
    "ax[2, 0].plot(stats[\"total_loss\"], label=\"total_loss\")\n",
    "# ax[2, 0].legend()\n",
    "\n",
    "ax[2, 1].set_title(\"Approx. KL-Divergence vs. Iteration\")\n",
    "ax[2, 1].plot(stats[\"approx_kl\"])\n",
    "\n",
    "ax[3, 0].set_title(\"Clip Fraction vs. Iteration\")\n",
    "ax[3, 0].plot(stats[\"clip_frac\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.evaluate(render=True, max_cycles=100, seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
