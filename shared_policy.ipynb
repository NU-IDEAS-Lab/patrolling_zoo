{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPO Integration\n",
    "\n",
    "This runs the integrated MAPPO algorithm with the patrolling zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from onpolicy.scripts.train.train_patrolling import get_config, parse_args, main\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_config()\n",
    "all_args = parse_args([], parser)\n",
    "\n",
    "all_args.experiment_name = \"sharedActor\"\n",
    "all_args.env_name = \"Patrolling\"\n",
    "all_args.user_name = \"ideas-mas\"\n",
    "\n",
    "all_args.num_agents = 2\n",
    "all_args.agent_speed = 10.0\n",
    "all_args.action_method = \"full\"\n",
    "all_args.observe_method = \"pyg\"\n",
    "all_args.observe_method_global = \"adjacency\"\n",
    "all_args.observation_radius = 200.0\n",
    "all_args.observation_bitmap_size = 40\n",
    "all_args.alpha = 0.1\n",
    "all_args.beta = 1.0\n",
    "# all_args.reward_method_terminal = \"averageAverage\"\n",
    "all_args.reward_method_terminal = \"none\"\n",
    "all_args.reward_interval = 1\n",
    "\n",
    "all_args.graph_name = \"2nodes\"\n",
    "all_args.graph_file = f\"patrolling_zoo/env/{all_args.graph_name}.graph\"\n",
    "all_args.num_env_steps = 10e5 * 1 #total number of steps\n",
    "all_args.episode_length = 200 #number of steps in a training episode\n",
    "all_args.max_cycles = all_args.episode_length #number of steps in an environment episode\n",
    "\n",
    "all_args.algorithm_name = \"mappo\"\n",
    "all_args.use_gnn_policy = True\n",
    "all_args.use_recurrent_policy = True\n",
    "all_args.use_naive_recurrent_policy = False\n",
    "all_args.use_centralized_V = True\n",
    "all_args.use_gae = False\n",
    "all_args.use_gae_amadm = True\n",
    "all_args.share_policy = True\n",
    "all_args.sep_share_policy = False\n",
    "all_args.share_reward = False\n",
    "all_args.skip_steps_sync = False\n",
    "all_args.skip_steps_async = False\n",
    "all_args.use_ReLU = False\n",
    "# all_args.lr = 1e-3\n",
    "# all_args.entropy_coef = 0.1\n",
    "all_args.hidden_size = 128\n",
    "\n",
    "all_args.n_rollout_threads = 1\n",
    "all_args.save_interval = 10\n",
    "all_args.cuda = True\n",
    "all_args.cuda_idx = 0\n",
    "\n",
    "all_args.use_wandb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u are choosing to use mappo, we set use_recurrent_policy & use_naive_recurrent_policy to be False\n",
      "choose to use gpu...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,2,1,128) into shape (1,2,1,128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mall_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/patrolling_zoo/onpolicy/scripts/train/train_patrolling.py:251\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args, parsed_args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     runner \u001b[38;5;241m=\u001b[39m Runner(config)\n\u001b[0;32m--> 251\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mfinish(exit_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/dev/patrolling_zoo/onpolicy/runner/shared/patrolling_runner.py:63\u001b[0m, in \u001b[0;36mPatrollingRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m obs, share_obs, rewards, dones, infos, values, actions, action_log_probs, rnn_states, rnn_states_critic, delta_steps\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# insert data into buffer\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# compute return and update network\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[0;32m~/dev/patrolling_zoo/onpolicy/runner/shared/patrolling_runner.py:174\u001b[0m, in \u001b[0;36mPatrollingRunner.insert\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    171\u001b[0m             rnn_states_critic[i][agent_id] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    172\u001b[0m             masks[i, agent_id] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshare_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshare_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnn_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrnn_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnn_states_critic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrnn_states_critic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_log_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_log_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_preds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrewards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeltaSteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelta_steps\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/patrolling_zoo/onpolicy/utils/shared_buffer.py:115\u001b[0m, in \u001b[0;36mSharedReplayBuffer.insert\u001b[0;34m(self, share_obs, obs, rnn_states, rnn_states_critic, actions, action_log_probs, value_preds, rewards, masks, bad_masks, active_masks, available_actions, deltaSteps, no_reset)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_obs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m share_obs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_states[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m rnn_states\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_states_critic[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m rnn_states_critic\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep] \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,2,1,128) into shape (1,2,1,128)"
     ]
    }
   ],
   "source": [
    "main([], parsed_args = all_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patrolling_zoo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
